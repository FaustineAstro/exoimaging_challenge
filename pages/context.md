Hereafter, we present a community-wide data challenge for exoplanets direct detection with ground-based high-contrast imaging. This challenge is *being* prepared in collaboration with several members of the high-contrast imaging community. This data challenge has direct support from the Grenoble Alpes Data Institute, France.

In the spirit of openness, anyone can contribute at any stage of the challenge by sending a pull request to this repository or an email to [carlos.gomez@univ-grenoble-alpes.fr](carlos.gomez@univ-grenoble-alpes.fr). All the benchmark datasets, metrics and results will be available at the end of the competition.

Direct imaging is the next big step in the hunt of extrasolar planets. Observing exoplanets using ground-based telescopes is a very challenging task. The main difficulties are the huge difference in brightness between the host star and its potential companions, the small angular separation between them, and the image degradation caused by the Earth's turbulent atmosphere. Therefore, ground-based high-contrast imaging relies on the use of adaptive optics for wavefront correction and coronagraphy for the suppression of light coming from the star. The following video, prepared by the NASA Exoplanet Exploration Program, explains in simple terms the role of coronagraphy and adaptive optics with deformable mirrors in high-contrast imaging.  

<iframe width="560" height="315" src="https://www.youtube.com/embed/SpzeS7KBGkw?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
<br><br>

The two remaining components of high-contrast imaging are the data acquisition techniques ([see the sub-challenges section](pages/subchallenges.md)) which focus on introducing some diversity in the data that later on can be exploited by the post-processing techniques. This last step of algorithmic speckle noise subtraction is what ultimately pushes the sensitivity of the exposures, and the detection limits of surveys and instruments. 

## Objectives

A multitude of image processing algorithms and pipelines for processing high contrast imaging data have been developed in the past thirteen years. The goal of this challenge is not only to compare, in a fair and robust way, existing algorithms but to spark new collaborations/ideas, share knowledge, and ultimately to maximize the scientific return of existing and future near-infrared high-contrast imaging instruments.

Computer science and machine learning fields have a long tradition conducting data challenges and competitions. Repositories of benchmark (curated) datasets are an integral part of the field of machine learning. We want to integrate these practices to the field of high-contrast imaging. In the future, the process of testing new algorithms will be much straightforward and robust, once the community adopts the standard metrics (with their open-source implementations) and the benchmark library resulting from this challenge.  

 


